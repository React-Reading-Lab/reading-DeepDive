## MLFQ

해당 스케줄러는 수년 동안 다듬어져 일부 현대 시스템에까지 발전되었다.

MLFQ가 해결하려고 하는 기본적인 문제

1. 짧은 작업을 먼저 실행시켜 반환시간을 최적화 하고자 한다.
2. 대화형 사용자에게 빠른 응답을 주도록 응답 시간을 최적화 한다.

_어떻게 프로세스에 대한 정보없이 위의 두가지 조건을 만족할 수 있을까?_

## 1. MLFQ 기본 규칙

MLFQ는 여러 개의 큐로 구성되면 각각 다른 우선순위가 배정된다.

Ready State Process는 여러 개의 큐 중 하나에 존재한다.

하나의 큐에 존재하는 프로세스들은 모두 같은 우선순위를 가진다. 해당 작업들 사이에서는 라운드 로비 스케줄링 알고리즘이 사용된다.

MLFQ의 핵심은 **우선순위 부여,**

단, 우선순위는 고정되는 것이 아니라 각 작업의 특성에 따라 **동적으로 우선순위를 부여한다.**

- 규칙 1: Priority(A) > Priority(B) 이면, A가 실행된다.
- 규칙 2: Priority(A) = Priority(B) 이면, A와 B는 RR방식으로 실행된다.

기본 규칙만을 가지고 있는 경우 기아 현상이 나타날 수 있다. (우선순위가 낮은 작업은 CPU를 점유하지 못 함)

하지만 MLFQ는 고정된 우선순위를 가지지 않고 우선순위가 동적으로 변한다. 이를 어떻게 하는지 알아보자.

## 2. 시도 1: 우선순위의 변경

MLFQ가 작업의 우선순위를 어떻게 바꿀 것인지 결정. 즉 작업이 존재하는 큐를 결정. 이를 위해서는 **워크로드의 특성**을 반영해야 한다.

워크로드의 특성: 짧은 실행 시간을 갖는 CPU를 자주 양보하는 대화형 작업, 많은 CPU 시간을 요구하지만 응답 시간은 중요하지 않은 긴 실행 시간의 CPU 위주의 작업이 혼재되어 있다.

- 규칙 3: 작업이 시스템에 진입하면, 가장 높은 우선순위, 즉 맨 위의 큐에 놓여진다.
- 규칙 4a: 주어진 타임 슬라이스를 모두 사용하면 우선순위는 낮아진다. 즉, 한 단계 아래 큐로 이동한다.
- 규칙 4b: 타임 슬라이스를 소진하기 전에 CPU를 양도하면 같은 우선순위를 유지한다.

### 예1: 한 개의 긴 실행 시간을 가진 작업의 우선순위 변화

![image.png](attachment:389f952f-4a5b-4d54-abfc-3755bdd84568:image.png)

### 예2: 짧은 작업과 함께

![image.png](attachment:fae016d0-c200-445d-9439-1abddf75bd19:image.png)

중간에 짧은 작업 시간을 가진 작업이 들어왔을 때. MLFQ는 SJF와 비슷하게 동작한다. 비록 프로세스의 작업시간은 모르지만 새로 들어온 작업을 가장 높은 우선순위 큐에 놓기 때문에 빠르게 실행되고 종료된다.

### 예3: 입출력 작업에 대해서는 어떻게?

규칙4b가 말하는 것 처럼 작업이 타임 슬라이스를 소모하기 전에 반환하면 같은 우선순위를 유지한다. 해당 규칙의 의도는 대화형 작업이 키보드나 마우스로부터 사용자 입력을 대기하며 자주 입출력을 수행하면 타임 슬라이스가 종료되기 전에 CPU를 양도하게 될 것이다.

![image.png](attachment:39da4bee-a9be-4333-8617-7ff107b55e9b:image.png)

### 현재 MLFQ의 문제점

CPU를 긴 작업들과 짧은 작업들 사이에 잘 공유하고, 입출력 중점 대화형 작업을 빨리 실행시키기 때문에 잘 동작하는 것처럼 보인다.

하지만 현재 MLFQ는 문제가 존재한다.

1. 기아 상태(starvation)가 발생한다. 시스템에 많은 대화형 작업이 존재하면 그들이 모든 CPU 시간을 소모하게 될 것이고 따라서 긴 실행 시간 작업은 CPU 시간을 할당받지 못할 것이다.

1. 프로그램이 타임 슬라이스가 끝나기 전 입출력 요청을 내려 CPU를 양도하게 프로그램을 작성하면 계속해서 높은 우선순위를 가지고 프로그램이 존재하게 된다.

1. 프로그램은 시간 흐름에 따라 특성이 변할 수 있다. CPU 위주 작업이 대화형 작업으로 바뀔 수 있다. 현재 구현 방식으로는 그런 작업은 운이 없게도 다른 대화형 작업과 같은 대우를 받을 수 없다.

### 시도 2: 우선순위의 상향 조정

규칙을 보완하여 기아 문제를 방지해보자. 간단한 아이디어는 주기적으로 모든 작업의 **우선순위를 상향 조정(boost)**하는 것이다.

- 규칙 5: 일정 기간 S가 지나면, 시스템의 모든 작업을 최상위 큐로 이동시킨다.
  새 규칙은 두 가지 문제를 한 번에 해결한다. 첫번째로 프로세스는 굶지 않는다는 것을 보장받는다.
  둘째, CPU 위주의 작업이 대화형 작업으로 특성이 변할 경우 우선순위 상향을 통해 스케줄러가 변경된 특성에 적합한 스케줄링 방법을 적용한다.
  물론 S 값의 결정이 필요하다. S를 얼마로 해야 하는가? 이러한 종류의 값을 부두 상수(voo-doo constants)라고 불렀다. S는 사실 정확하게 구할 수 없다.

### 시도 3: 더 나은 시간 측정

해결해야 할 문제가 하나 더 있다. 스케줄러를 자신에게 유리하게 동작시키는 것을 어떻게 막을 것인가?

여기서의 해결책은 MLFQ의 각 단계에서 **CPU 총 사용 시간을 측정**하는 것이다.

스케줄러는 현재 단계에서 프로세스가 소진한 CPU 사용 시간을 저장한다. 프로세스가 타임 슬라이스에 해당하는 시간을 모두 소진하면 다음 우선순위 큐로 강등된다. 즉 타임 슬라이스를 한번에 다 쓰든 여러번에 걸쳐 쓰든 타임 슬라이스를 소진하면 강등된다.

- 규칙 4: 주어진 단계에서 시간 할당량을 소진하면 우선순위는 낮아진다.

![image.png](attachment:616ebdf2-7e9e-4e57-9d46-6724a3952149:image.png)

### 5. MLFQ 조정과 다른 쟁점들

MLFQ 스케줄링에는 여러 다른 쟁점들이 남아 있다. 필요한 변수들을 스케줄러가 어떻게 설정해야 하는지도 중요한 문제다.

예를 들어, 몇 개의 큐가 존재해야 하는가? 큐당 타임 슬라이스의 크기는 얼마로 해야 하는가? boost의 주기는 얼마나 해야 하는가?

## 추가 학습

- 실제 운영체제에서 큐는 몇개나 존재하는가
- 여러 개의 큐를 프로세스가 이동하는 경우 캐시 HITS 횟수가 줄어드는 문제가 있음
  - 이를 어떻게 해결하고 있는가?
  - L1, L2 캐시?

```
MLFQ나 RR의 경우 잦은 컨텍스트 스위칭이 발생한다.
이는 당연히 오버헤드가 존재하지만 발생하는 오버헤드 중에서 캐시 메모리 성능 저하가 있을 것이다.

매번 실행되는 프로세스가 변경되기 때문에 Cache Hit Rate가 떨어지게 된다.
```

이를 해결 또는 완화할 수 있는 방법

```
- Time Slice 크기 조절: 길이 짧아질수록 캐시 미스도 잦아진다. 하지만 길이가 길어지면
 response time이 길어지기 때문에 반응성이 떨어진다.

	현대 OS는 대게 동적인 방식으로 Time Slice 길이를 택한다. 대표적으로 리눅스의 CFS 스케줄러가 있다.

- 캐시 파티셔닝: 특정 하드웨어에서는 프로세스 별 캐시 공간을 미리 할당하는 방식. 이는 하드웨어의 지원이 필요
	유연성?이 떨어진다.

- Cache Warming: 컨텍스트 스위칭이 발생하기 전에 다음 프로세스가 사용할 데이터를 미리 캐시에 로드하는 기법
	캐시 미스를 줄일 수는 있지만 스케줄링 오버헤드 증가 가능

- CPU Affinity: 스케줄러는 특정 프로세스를 가능한 한 동일한 CPU 코어에 할당하여 캐시 메모리가 유지되도록 한다.

```

### 캐시 계층 알아보기

캐시 계층은 CPU와 메인 메모리(RAM) 사이의 속도 차이를 줄이기 위해 여러 단계로 구성된 메모리 시스템

CPU와 멀어질수록 상대적으로 속도는 느려지고 용량은 증가한다.

**캐시 계층 구조**

- L1 캐시 (Level 1 Cache): CPU 코어 내부에 직접 내장되어 있어 CPU가 가장 빠르게 접근할 수 있다. L1 캐시는 일반적으로 L1i(명령어 캐시), L1d(데이터 캐시)로 나뉘어져 있다. **L1 캐시는 CPU 코어 당 할당되는 경우 일반적이다. 다른 코어나 프로세스와 캐시를 공유하지 않는다.**
- L2 캐시: CPU 코어 근처에 위치. **L2 캐시는 코어당 할당되거나 여러 코어가 공유하는 구조를 가질 수 있다.**
- L3 캐시: 모든 CPU **코어가 공유하는 공용 캐시**이다. 메인 메모리로의 접근을 최소화하는 최종 버퍼 역할을 한다.

### CFS Scheduler

CFS는 타임 슬라이스 대신 가상 실행 시간(vruntime) 개념을 사용한다. 각 프로세스는 실행될 때마다 vruntime이 증가하며, CFS는 vruntime이 가장 작은 프로세스를 다음에 실행하도록 선택합니다.

- vruntime: 프로세스가 CPU를 사용한 시간.
- 우선순위 (Nice Value): 프로세스의 우선순위는 vruntime의 증가 속도에 영향을 준다. 우선순위가 높은(nice value가 낮은) 프로세스는 vruntime이 천천히 증가하므로 더 자주 실행 기회를 얻는다.
- RBTree: CFS는 실행 가능한 모든 프로세스를 vruntime을 기준으로 정렬된 레드-블랙 트리로 관리한다. CFS는 이 트리의 가장 왼쪽 노드(vruntime이 가장 작은 노드)를 항상 다음 실행 대상으로 선택한다.
- Preemption: 만약 새로 실행 가능한 프로세스가 등장했을 때 그 프로세스이 vruntime이 현재 실행 중인 프로세스의 vruntime보다 작다면 실행 중인 프로세스를 중단하고 새로운 프로세스를 실행시킨다.
- IO 작업: 프로세스가 IO 작업을 위해 CPU를 반납하면 해당 프로세스는 rbtree에서 제거되고 작업이 끝나면 다시 트리로 삽입된다.
